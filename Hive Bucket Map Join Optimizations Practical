# Hive Join Optimizations

Hive Join Optimizations:
3 important kind of join optimizations:
1.	Map Side Join (is very important)
2.	Bucket Map Join
3.	SMB (Sort Merge Bucket Join)

•	There is no reduce phase. The entire joining activity will happen at the mapper end.

Can we always have a join as map side join?
However if certain criteria matches then we go for mapside join.

We want to join 2 tables
•	Out of 2 tables, one table should be smaller so that it can fit in memory of datanode.

We want to join 3 or more tables
•	All the tables except one are smaller to fit in memory 

Consider we have 2 tables
1.	Orders
2.	Customers
One of them is big table and other is small table


In mysql in cloudera there is a database called as retail_db
This database has orders and customers table
We need to get data from these 2 tables which are available in mysql and we want to import it to hdfs.

1.	Sqoop Import to get orders and customers data in hdfs.
2.	Create hive external tables on top of this hdfs data.

#Importing the 2 datasets orders and customers from mysql located in retail_db database
sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--warehouse-dir /user/cloudera

sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table customers \
--warehouse-dir /user/cloudera


[cloudera@quickstart ~]$ sqoop import \
> --connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
> --username retail_dba \
> --password cloudera \
> --table orders \
> --warehouse-dir /user/cloudera

# To Check orders table that was imported
[cloudera@quickstart ~]$ hadoop fs -ls
Found 7 items
drwxr-xr-x   - cloudera cloudera          0 2022-09-09 23:31 dir1
drwxr-xr-x   - cloudera cloudera          0 2022-09-16 05:55 inputfolder
drwxr-xr-x   - cloudera cloudera          0 2022-09-18 03:04 mapred_input
drwxr-xr-x   - cloudera cloudera          0 2022-09-18 03:28 mapred_output
drwxr-xr-x   - cloudera cloudera          0 2022-10-09 00:36 orders
drwxr-xr-x   - cloudera cloudera          0 2022-09-16 06:27 outputfolder
-rw-r--r--   1 cloudera cloudera       1355 2022-10-01 21:04 udf_example.jar

[cloudera@quickstart ~]$ hadoop fs -ls orders
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2022-10-09 00:36 orders/_SUCCESS
-rw-r--r--   1 cloudera cloudera     741614 2022-10-09 00:36 orders/part-m-00000
-rw-r--r--   1 cloudera cloudera     753022 2022-10-09 00:36 orders/part-m-00001
-rw-r--r--   1 cloudera cloudera     752368 2022-10-09 00:36 orders/part-m-00002
-rw-r--r--   1 cloudera cloudera     752940 2022-10-09 00:36 orders/part-m-00003


[cloudera@quickstart ~]$ sqoop import \
> --connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
> --username retail_dba \
> --password cloudera \
> --table customers \
> --warehouse-dir /user/cloudera


[cloudera@quickstart ~]$ hadoop fs -ls
Found 8 items
drwxr-xr-x   - cloudera cloudera          0 2022-10-09 00:42 customers
drwxr-xr-x   - cloudera cloudera          0 2022-09-09 23:31 dir1
drwxr-xr-x   - cloudera cloudera          0 2022-09-16 05:55 inputfolder
drwxr-xr-x   - cloudera cloudera          0 2022-09-18 03:04 mapred_input
drwxr-xr-x   - cloudera cloudera          0 2022-09-18 03:28 mapred_output
drwxr-xr-x   - cloudera cloudera          0 2022-10-09 00:36 orders
drwxr-xr-x   - cloudera cloudera          0 2022-09-16 06:27 outputfolder
-rw-r--r--   1 cloudera cloudera       1355 2022-10-01 21:04 udf_example.jar


[cloudera@quickstart ~]$ hadoop fs -ls customers
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2022-10-09 00:42 customers/_SUCCESS
-rw-r--r--   1 cloudera cloudera     237145 2022-10-09 00:42 customers/part-m-00000
-rw-r--r--   1 cloudera cloudera     237965 2022-10-09 00:42 customers/part-m-00001
-rw-r--r--   1 cloudera cloudera     238092 2022-10-09 00:42 customers/part-m-00002
-rw-r--r--   1 cloudera cloudera     240323 2022-10-09 00:42 customers/part-m-00003


2.	Create hive external tables on top of this hdfs data.

# Connect to hive

hive> create database bigdatabysumit;
OK
Time taken: 2.436 seconds

hive> show databases;
OK
bigdatabysumit
default
trendy
trendytech
Time taken: 0.955 seconds, Fetched: 4 row(s)

hive> use bigdatabysumit;
OK
Time taken: 0.116 seconds

# Create Hive external tables

CREATE external TABLE orders(
order_id int,
order_date string,
order_customer_id int,
order_status string)
row format delimited fields terminated by ','
stored as textfile
location '/user/cloudera/orders';

CREATE external TABLE customers(
customer_id int,
customer_fname string,
customer_lname string,
customer_email string,
customer_password string,
customer_street string,
customer_city string,
customer_state string,
customer_zipcode string)
row format delimited fields terminated by ','
stored as textfile
location '/user/cloudera/customers';


hive> CREATE external TABLE orders(
    > order_id int,
    > order_date string,
    > order_customer_id int,
    > order_status string)
    > row format delimited fields terminated by ','
    > stored as textfile
    > location '/user/cloudera/orders';
OK
Time taken: 0.508 seconds

hive> select * from orders limit 5;
OK
1	2013-07-25 00:00:00.0	11599	CLOSED
2	2013-07-25 00:00:00.0	256	PENDING_PAYMENT
3	2013-07-25 00:00:00.0	12111	COMPLETE
4	2013-07-25 00:00:00.0	8827	CLOSED
5	2013-07-25 00:00:00.0	11318	COMPLETE
Time taken: 1.611 seconds, Fetched: 5 row(s)

hive> select count(*) from orders;


hive> CREATE external TABLE customers(
    > customer_id int,
    > customer_fname string,
    > customer_lname string,
    > customer_email string,
    > customer_password string,
    > customer_street string,
    > customer_city string,
    > customer_state string,
    > customer_zipcode string)
    > row format delimited fields terminated by ','
    > stored as textfile
    > location '/user/cloudera/customers';
OK
Time taken: 0.487 seconds

hive> select * from customers limit 5;
OK
1	Richard	Hernandez	XXXXXXXXX	XXXXXXXXX	6303 Heather Plaza	Brownsville	TX	78521
2	Mary	Barrett	XXXXXXXXX	XXXXXXXXX	9526 Noble Embers Ridge	Littleton	CO	80126
3	Ann	Smith	XXXXXXXXX	XXXXXXXXX	3422 Blue Pioneer Bend	Caguas	PR	00725
4	Mary	Jones	XXXXXXXXX	XXXXXXXXX	8324 Little Common	San Marcos	CA	92069
5	Robert	Hudson	XXXXXXXXX	XXXXXXXXX	10 Crystal River Mall 	Caguas	PR	00725
Time taken: 1.451 seconds, Fetched: 5 row(s)

# JOINS check the value of property hive.auto.covert.join

set hive.auto.convert.join;
set hive.auto.convert.join=false;
set hive.auto.convert.join;


hive> set hive.auto.convert.join;
hive.auto.convert.join=true
hive> set hive.auto.convert.join=false;
hive> set hive.auto.convert.join;
hive.auto.convert.join=false

# Try running the join query now

SELECT c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o JOIN customers c ON (
o.order_customer_id = c.customer_id) limit 10;

hive> SELECT c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o JOIN customers c ON (
    > o.order_customer_id = c.customer_id) limit 10;

# Now let us try to execute inner joins as map side join

Enable the property
set hive.auto.convert.join=true;

hive> set hive.auto.convert.join=true;
hive> set hive.auto.convert.join
    > ;
hive.auto.convert.join=true


# Run the query again
SELECT c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o JOIN customers c ON (
o.order_customer_id = c.customer_id) limit 10;

•	In case of Map side join before starting the mapreduce job it will do a local task first.
•	What is this local task?
Getting the smaller table and putting it in the memory of each node as a hashtable.
(123, {all other columns})
(124, {all other columns})

When the property hive.auto.convert.join is set to true. Then in this case hive is treating is as a map side join because the conditions are met.
One of the table is small enough to fit in memory.
What is the definition of small table?
Any table which is less than 25mb is considered to be small table.

In the previous case since we set the property then hive will automatically convert this join as map side join.
But what if we do not want to go with automatic conversion.
Rather we want to specify using some hints.


#Set the hint manually to invoke map side join

set hive.auto.convert.join=false;
set hive.ignore.mapjoin.hint;
hive.ignore.mapjoin.hint=true
set hive.ignore.mapjoin.hint=false;


hive> set hive.ignore.mapjoin.hint;
hive.ignore.mapjoin.hint=true
hive> set hive.ignore.mapjoin.hint;
hive.ignore.mapjoin.hint=false

# Now let us try to execute inner join as map side join using hints indicating left table is small

SELECT /*+ MAPJOIN(orders) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o JOIN customers c ON (
o.order_customer_id = c.customer_id) limit 5;

hive> SELECT /*+ MAPJOIN(orders) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o JOIN customers c ON (
    > o.order_customer_id = c.customer_id) limit 5;

# Now let us try to execute inner join as map side join using hints indicating right table is small

SELECT /*+ MAPJOIN(customers) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o JOIN customers c ON (
o.order_customer_id = c.customer_id) limit 5;


# Hive Join Optimizations Practical-2

•	Map Side Joins

Created 2 external hive tables
•	Orders
•	Customers

1.	Set the auto map join property to false and we saw that reducer is coming to play
2.	We set the property to true and then we can see that there were 0 reducers.
3.	We set the auto map join property to false we said that hints should not be ignored.
4.	In hint we mentioned the left table
5.	In hint we mentioned the right table.
6.	Inner joins are possible as map side join when one table is small enough to fit in memory
7.	In both the cases
•	Left table is small
•	Right table is small
8.	Inner join was treated as map side join.
Conclusion: inner joins can be treated as map side join when left table/right table is small enough to fit in memory.


1.	Inner Join : All matching records from both the table
2.	Left Outer Join: All the matching records from both the tables + all the records from the left table which do not have a match.
3.	Right Outer Join: All the matching records from both the tables + all the records from right table which do not have a match.
4.	Full Outer Join: Union of left outer and right outer join

Scenario-1: can a left outer join be treated as map side join when left table is small?
Conclusion: No
Scenario-2: can a right outer join be treated as map side join when left table is small?
Conclusion: Yes
Scenario-3: can a right outer join be treated as map side join when right table is small?
Conclusion: No
Scenario-4: can a left outer join be treated as map side join when right table is small?
Conclusion: Yes

#Left Outer Join as map side join when left table is small

SELECT /*+ MAPJOIN(orders) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o LEFT OUTER JOIN customers c ON (
o.order_customer_id = c.customer_id) limit 5;


#Right Outer Join as a map side join when left table is small
SELECT /*+ MAPJOIN(orders) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o RIGHT OUTER JOIN customers c ON (
o.order_customer_id = c.customer_id) limit 5;

hive> SELECT /*+ MAPJOIN(orders) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o RIGHT OUTER JOIN customers c ON (
    > o.order_customer_id = c.customer_id) limit 5;
    
    
# Left Outer Join as a Map Side Join When right table is small

SELECT /*+ MAPJOIN(customers) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o LEFT OUTER JOIN customers c ON (
o.order_customer_id = c.customer_id) limit 5;


•	If left table is small then left outer join will fail and right outer join will work
•	If right table is small then left outer join will work and right outer join will fail
•	Full outer join won’t work

Note: A full outer join cannot be treated as map side join in any case.

# Full Outer Join as Map Side Join
SELECT /*+ MAPJOIN(customers) */ c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM orders o FULL OUTER JOIN customers c ON (
o.order_customer_id = c.customer_id) limit 5;

# What is a small table as per hive?

There is a property:
hive.mapjoin.smalltable.filesize

The value of this property indicates the size. If a file is having lesser size than it is considered as small size.

set hive.mapjoin.smalltable.filesize;
hive.mapjoin.smalltable.filesize=25000000

hive> set hive.mapjoin.smalltable.filesize;
hive.mapjoin.smalltable.filesize=25000000


# Bucket Map Join:

Bucket Map Join:
•	What if you have 2 big tables?
•	Map side join won’t work
•	In this case you can go for Bucket Map Join
Constraints:
1.	Both the tables should be bucketed on join column
Customers table should be bucketed on customer_id.
Orders table should be bucketed on order_customer_id
2.	Number of buckets in bigger table should be an integral multiple of number of buckets in smaller table
If small table has 4 buckets 
Then large table can have 4, 8, 12,16 buckets

# We need to enable the Bucketing Map Join

set hive.enforce.bucketing;

hive> set hive.enforce.bucketing;
hive.enforce.bucketing=false
hive> set hive.enforce.bucketing=true;
hive> set hive.enforce.bucketing;
hive.enforce.bucketing=true

# Create the first Table (bucketed) in Hive

CREATE external TABLE customers_bucketed(
customer_id int,
customer_fname string,
customer_lname string,
customer_email string,
customer_password string,
customer_street string,
customer_city string,
customer_state string,
customer_zipcode string) clustered
by(customer_id) into 4 buckets row format delimited fields terminated BY ',';


hive> CREATE external TABLE customers_bucketed(
    > customer_id int,
    > customer_fname string,
    > customer_lname string,
    > customer_email string,
    > customer_password string,
    > customer_street string,
    > customer_city string,
    > customer_state string,
    > customer_zipcode string) clustered
    > by(customer_id) into 4 buckets row format delimited fields terminated BY ',';
OK
Time taken: 0.217 seconds

# Loading data from normal table to bucketed table

insert into customers_bucketed select * from customers;

# Create the second Table (bucketed) in Hive

CREATE external TABLE orders_bucketed(
order_id int,
order_date string,
order_customer_id int,
order_status string) clustered
by(order_customer_id) into 8 buckets row format delimited fields terminated BY ',';

hive> CREATE external TABLE orders_bucketed(
    > order_id int,
    > order_date string,
    > order_customer_id int,
    > order_status string) clustered
    > by(order_customer_id) into 8 buckets row format delimited fields terminated BY ',';
OK
Time taken: 0.209 seconds

# Loading the data into orders_bucketed table
insert into orders_bucketed select * from orders;


When we created the external table we didn’t specify any location. That is why the data should be in default directory

/user/hive/warehouse/bigdatabysumit.db/customers_bucketed
/user/hive/warehouse/bigdatabysumit.db/orders_bucketed


[cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse/bigdatabysumit.db/customers_bucketed
Found 4 items
-rwxrwxrwx   1 cloudera supergroup     238225 2022-10-09 04:29 /user/hive/warehouse/bigdatabysumit.db/customers_bucketed/000000_0
-rwxrwxrwx   1 cloudera supergroup     238627 2022-10-09 04:29 /user/hive/warehouse/bigdatabysumit.db/customers_bucketed/000001_0
-rwxrwxrwx   1 cloudera supergroup     238066 2022-10-09 04:29 /user/hive/warehouse/bigdatabysumit.db/customers_bucketed/000002_0
-rwxrwxrwx   1 cloudera supergroup     238607 2022-10-09 04:29 /user/hive/warehouse/bigdatabysumit.db/customers_bucketed/000003_0

[cloudera@quickstart ~]$ hadoop fs -ls /user/hive/warehouse/bigdatabysumit.db/orders_bucketed
Found 8 items
-rwxrwxrwx   1 cloudera supergroup     375671 2022-10-09 04:36 /user/hive/warehouse/bigdatabysumit.db/orders_bucketed/000000_0
-rwxrwxrwx   1 cloudera supergroup     376056 2022-10-09 04:36 /user/hive/warehouse/bigdatabysumit.db/orders_bucketed/000001_0
-rwxrwxrwx   1 cloudera supergroup     374213 2022-10-09 04:36 /user/hive/warehouse/bigdatabysumit.db/orders_bucketed/000002_0
-rwxrwxrwx   1 cloudera supergroup     373129 2022-10-09 04:36 /user/hive/warehouse/bigdatabysumit.db/orders_bucketed/000003_0
-rwxrwxrwx   1 cloudera supergroup     378911 2022-10-09 04:36 /user/hive/warehouse/bigdatabysumit.db/orders_bucketed/000004_0
-rwxrwxrwx   1 cloudera supergroup     379362 2022-10-09 04:36 /user/hive/warehouse/bigdatabysumit.db/orders_bucketed/000005_0
-rwxrwxrwx   1 cloudera supergroup     374670 2022-10-09 04:39 /user/hive/warehouse/bigdatabysumit.db/orders_bucketed/000006_0
-rwxrwxrwx   1 cloudera supergroup     367932 2022-10-09 04:39 /user/hive/warehouse/bigdatabysumit.db/orders_bucketed/000007_0


hive> select * from customers_bucketed limit 5;
OK
1556	Mary	Smith	XXXXXXXXX	XXXXXXXXX	4746 Quaking Bear Valley	Las VegasNV	89117
3304	Amanda	Gibson	XXXXXXXXX	XXXXXXXXX	7894 Old Circle	Chicago	IL	60630
4664	Mary	Cole	XXXXXXXXX	XXXXXXXXX	2991 Silver Circuit	Caguas	PR	00725
9324	Willie	Parker	XXXXXXXXX	XXXXXXXXX	4388 Burning Goose Ridge	Madison	WI	53704
3888	Scott	Robles	XXXXXXXXX	XXXXXXXXX	5104 Jagged Park	Miami	FL	33162
Time taken: 0.134 seconds, Fetched: 5 row(s)


hive> select * from orders_bucketed limit 5;
OK
67783	2013-11-06 00:00:00.0	11872	COMPLETE
3466	2013-08-14 00:00:00.0	10312	PENDING_PAYMENT
22288	2013-12-08 00:00:00.0	6016	CANCELED
51560	2014-06-13 00:00:00.0	832	CLOSED
31594	2014-02-05 00:00:00.0	10888	COMPLETE
Time taken: 0.116 seconds, Fetched: 5 row(s)



# Set the below property 

There is a property:
set hive.optimize.bucketmapjoin

We need to set it to true
set hive.optimize.bucketmapjoin=true;

hive> set hive.optimize.bucketmapjoin;
hive.optimize.bucketmapjoin=true

# Now try running the join query on bucketed tables

SELECT c.customer_id, c.customer_fname, c.customer_lname, o.order_id, o.order_date FROM customers_bucketed c JOIN orders_bucketed o ON (
c.customer_id = o.order_customer_id) limit 10;

# The auto convert property is not set; we can set the auto convert property

set hive.auto.convert.join;

# Sort Merge Bucket Map Join (SMB)

Conditions for Sort Merge Bucket join (SMB):
1.	Both the tables should be bucketed on the join column
2.	Number of buckets in larger table should be exactly equal to number of buckets in the smaller table
3.	Data in both tables should be sorted based on join column.
Note: Here both the tables can be large as well.
So let us try to see an example. We need to create 2 tables bucketed on join column. We will have same number of buckets in both tables.






# Hive Join Optimizations

Hive Join Optimizations:
3 important kind of join optimizations:
1.	Map Side Join (is very important)
2.	Bucket Map Join
3.	SMB (Sort Merge Bucket Join)

•	There is no reduce phase. The entire joining activity will happen at the mapper end.

Can we always have a join as map side join?
However if certain criteria matches then we go for mapside join.

We want to join 2 tables
•	Out of 2 tables, one table should be smaller so that it can fit in memory of datanode.

We want to join 3 or more tables
•	All the tables except one are smaller to fit in memory 

Consider we have 2 tables
1.	Orders
2.	Customers
One of them is big table and other is small table


In mysql in cloudera there is a database called as retail_db
This database has orders and customers table
We need to get data from these 2 tables which are available in mysql and we want to import it to hdfs.

1.	Sqoop Import to get orders and customers data in hdfs.
2.	Create hive external tables on top of this hdfs data.

#Importing the 2 datasets orders and customers from mysql located in retail_db database
sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table orders \
--warehouse-dir /user/cloudera

sqoop import \
--connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
--username retail_dba \
--password cloudera \
--table customers \
--warehouse-dir /user/cloudera


[cloudera@quickstart ~]$ sqoop import \
> --connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
> --username retail_dba \
> --password cloudera \
> --table orders \
> --warehouse-dir /user/cloudera

# To Check orders table that was imported
[cloudera@quickstart ~]$ hadoop fs -ls
Found 7 items
drwxr-xr-x   - cloudera cloudera          0 2022-09-09 23:31 dir1
drwxr-xr-x   - cloudera cloudera          0 2022-09-16 05:55 inputfolder
drwxr-xr-x   - cloudera cloudera          0 2022-09-18 03:04 mapred_input
drwxr-xr-x   - cloudera cloudera          0 2022-09-18 03:28 mapred_output
drwxr-xr-x   - cloudera cloudera          0 2022-10-09 00:36 orders
drwxr-xr-x   - cloudera cloudera          0 2022-09-16 06:27 outputfolder
-rw-r--r--   1 cloudera cloudera       1355 2022-10-01 21:04 udf_example.jar

[cloudera@quickstart ~]$ hadoop fs -ls orders
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2022-10-09 00:36 orders/_SUCCESS
-rw-r--r--   1 cloudera cloudera     741614 2022-10-09 00:36 orders/part-m-00000
-rw-r--r--   1 cloudera cloudera     753022 2022-10-09 00:36 orders/part-m-00001
-rw-r--r--   1 cloudera cloudera     752368 2022-10-09 00:36 orders/part-m-00002
-rw-r--r--   1 cloudera cloudera     752940 2022-10-09 00:36 orders/part-m-00003


[cloudera@quickstart ~]$ sqoop import \
> --connect jdbc:mysql://quickstart.cloudera:3306/retail_db \
> --username retail_dba \
> --password cloudera \
> --table customers \
> --warehouse-dir /user/cloudera


[cloudera@quickstart ~]$ hadoop fs -ls
Found 8 items
drwxr-xr-x   - cloudera cloudera          0 2022-10-09 00:42 customers
drwxr-xr-x   - cloudera cloudera          0 2022-09-09 23:31 dir1
drwxr-xr-x   - cloudera cloudera          0 2022-09-16 05:55 inputfolder
drwxr-xr-x   - cloudera cloudera          0 2022-09-18 03:04 mapred_input
drwxr-xr-x   - cloudera cloudera          0 2022-09-18 03:28 mapred_output
drwxr-xr-x   - cloudera cloudera          0 2022-10-09 00:36 orders
drwxr-xr-x   - cloudera cloudera          0 2022-09-16 06:27 outputfolder
-rw-r--r--   1 cloudera cloudera       1355 2022-10-01 21:04 udf_example.jar


[cloudera@quickstart ~]$ hadoop fs -ls customers
Found 5 items
-rw-r--r--   1 cloudera cloudera          0 2022-10-09 00:42 customers/_SUCCESS
-rw-r--r--   1 cloudera cloudera     237145 2022-10-09 00:42 customers/part-m-00000
-rw-r--r--   1 cloudera cloudera     237965 2022-10-09 00:42 customers/part-m-00001
-rw-r--r--   1 cloudera cloudera     238092 2022-10-09 00:42 customers/part-m-00002
-rw-r--r--   1 cloudera cloudera     240323 2022-10-09 00:42 customers/part-m-00003


2.	Create hive external tables on top of this hdfs data.

# Connect to hive

hive> create database bigdatabysumit;
OK
Time taken: 2.436 seconds

hive> show databases;
OK
bigdatabysumit
default
trendy
trendytech
Time taken: 0.955 seconds, Fetched: 4 row(s)

hive> use bigdatabysumit;
OK
Time taken: 0.116 seconds

# Create Hive external tables

CREATE exteranl TABLE orders(
order_id int,
order_date string,
order_customer_id int,
order_status string)
row format delimited fields terminated by ','
stored as textfile
location '/user/cloudera/orders';

CREATE external TABLE customers(
customer_id int,
customer_fname string,
customer_lname string,
customer_email string,
customer_password string,
customer_street string,
customer_city string,
customer_state string,
customer_zipcode string)
row format delimited fields terminated by ','
stored as textfile
location '/user/cloudera/customers';





